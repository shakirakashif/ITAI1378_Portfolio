{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c041126c-664f-491d-a5fd-8f78be978c33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (1.23.5)\n",
      "Requirement already satisfied: tensorflow in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (2.17.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (3.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: setuptools in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (68.0.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (1.65.4)\n",
      "Requirement already satisfied: packaging in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (0.37.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (2.17.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: optree in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: namex in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: rich in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from keras>=3.2.0->tensorflow) (13.8.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.19)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
      "Requirement already satisfied: keras in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (3.5.0)\n",
      "Requirement already satisfied: ml-dtypes in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from keras) (0.4.1)\n",
      "Requirement already satisfied: h5py in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from keras) (3.11.0)\n",
      "Requirement already satisfied: absl-py in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from keras) (2.1.0)\n",
      "Requirement already satisfied: packaging in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from keras) (24.1)\n",
      "Requirement already satisfied: numpy in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from keras) (1.23.5)\n",
      "Requirement already satisfied: optree in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from keras) (0.12.1)\n",
      "Requirement already satisfied: rich in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from keras) (13.8.1)\n",
      "Requirement already satisfied: namex in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from optree->keras) (4.12.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from rich->keras) (2.18.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from rich->keras) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
      "Requirement already satisfied: gym in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (0.23.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from gym) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from gym) (2.2.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from gym) (1.23.5)\n",
      "Requirement already satisfied: pygame in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (2.6.1)\n",
      "Requirement already satisfied: opencv-python in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from opencv-python) (1.23.5)\n",
      "Requirement already satisfied: pillow in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (9.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "!pip install tensorflow\n",
    "!pip install keras\n",
    "!pip install gym\n",
    "!pip install pygame\n",
    "!pip install opencv-python\n",
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "6a2411da-73bf-48c0-8a01-a85d9b893809",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ntasfi/PyGame-Learning-Environment.git\n",
      "  Cloning https://github.com/ntasfi/PyGame-Learning-Environment.git to /tmp/pip-req-build-pt38if0z\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/ntasfi/PyGame-Learning-Environment.git /tmp/pip-req-build-pt38if0z\n",
      "  Resolved https://github.com/ntasfi/PyGame-Learning-Environment.git to commit 3dbe79dc0c35559bb441b9359948aabf9bb3d331\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from ple==0.0.1) (1.23.5)\n",
      "Requirement already satisfied: Pillow in /anaconda/envs/azureml_py38/lib/python3.10/site-packages (from ple==0.0.1) (9.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/ntasfi/PyGame-Learning-Environment.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "e1c351c6-7b38-4e3c-80e1-b47e39282351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import cv2\n",
    "import random\n",
    "import gc\n",
    "import tensorflow as tf\n",
    "\n",
    "# Deep learning imports\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input, Concatenate, Conv2D, Lambda, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Lambda\n",
    "\n",
    "# Game environment\n",
    "from ple import PLE\n",
    "from ple.games.flappybird import FlappyBird\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['SDL_AUDIODRIVER'] = 'dummy'\n",
    "\n",
    "def setup_flappy_bird_environment():\n",
    "    \"\"\"Setup Flappy Bird environment and download required assets\"\"\"\n",
    "    import ple\n",
    "    ple_path = os.path.dirname(ple.__file__)\n",
    "    asset_path = os.path.join(ple_path, 'games', 'flappybird', 'assets')\n",
    "    os.makedirs(asset_path, exist_ok=True)\n",
    "    \n",
    "    assets = {\n",
    "        # Basic assets\n",
    "        'background-day.png': 'https://raw.githubusercontent.com/ntasfi/PyGame-Learning-Environment/master/ple/games/flappybird/assets/background-day.png',\n",
    "        'background-night.png': 'https://raw.githubusercontent.com/ntasfi/PyGame-Learning-Environment/master/ple/games/flappybird/assets/background-night.png',\n",
    "        'base.png': 'https://raw.githubusercontent.com/ntasfi/PyGame-Learning-Environment/master/ple/games/flappybird/assets/base.png',\n",
    "        'pipe-green.png': 'https://raw.githubusercontent.com/ntasfi/PyGame-Learning-Environment/master/ple/games/flappybird/assets/pipe-green.png',\n",
    "        'pipe-red.png': 'https://raw.githubusercontent.com/ntasfi/PyGame-Learning-Environment/master/ple/games/flappybird/assets/pipe-red.png',\n",
    "        \n",
    "        # Bird variants\n",
    "        'bluebird-upflap.png': 'https://raw.githubusercontent.com/ntasfi/PyGame-Learning-Environment/master/ple/games/flappybird/assets/bluebird-upflap.png',\n",
    "        'bluebird-midflap.png': 'https://raw.githubusercontent.com/ntasfi/PyGame-Learning-Environment/master/ple/games/flappybird/assets/bluebird-midflap.png',\n",
    "        'bluebird-downflap.png': 'https://raw.githubusercontent.com/ntasfi/PyGame-Learning-Environment/master/ple/games/flappybird/assets/bluebird-downflap.png',\n",
    "    }\n",
    "    \n",
    "    for filename, url in assets.items():\n",
    "        file_path = os.path.join(asset_path, filename)\n",
    "        if not os.path.exists(file_path):\n",
    "            print(f\"Downloading {filename}...\")\n",
    "            try:\n",
    "                urllib.request.urlretrieve(url, file_path)\n",
    "                print(f\"Successfully downloaded {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to download {filename}: {e}\")\n",
    "                return None\n",
    "    \n",
    "    # Create symbolic links for other bird variants\n",
    "    bird_colors = ['red', 'yellow']\n",
    "    flap_types = ['upflap', 'midflap', 'downflap']\n",
    "    \n",
    "    for color in bird_colors:\n",
    "        for flap in flap_types:\n",
    "            src = os.path.join(asset_path, f\"bluebird-{flap}.png\")\n",
    "            dst = os.path.join(asset_path, f\"{color}bird-{flap}.png\")\n",
    "            if not os.path.exists(dst):\n",
    "                os.symlink(src, dst)\n",
    "    \n",
    "    return asset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "a6756ea1-cf8a-470a-9e5c-3d9f029cb880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug function to verify assets\n",
    "def verify_assets():\n",
    "    \"\"\"\n",
    "    Verify that all required assets are present in the correct location\n",
    "    \"\"\"\n",
    "    import ple\n",
    "    ple_path = os.path.dirname(ple.__file__)\n",
    "    asset_path = os.path.join(ple_path, 'games', 'flappybird', 'assets')\n",
    "    \n",
    "    print(f\"Asset path: {asset_path}\")\n",
    "    print(f\"Asset directory exists: {os.path.exists(asset_path)}\")\n",
    "    \n",
    "    if os.path.exists(asset_path):\n",
    "        print(\"Contents of asset directory:\")\n",
    "        files = os.listdir(asset_path)\n",
    "        print(\"\\n\".join(sorted(files)))\n",
    "        \n",
    "        # Check for all required variants\n",
    "        bird_variants = ['blue', 'red', 'yellow']\n",
    "        flap_types = ['upflap', 'midflap', 'downflap']\n",
    "        \n",
    "        for bird in bird_variants:\n",
    "            for flap in flap_types:\n",
    "                filename = f\"{bird}bird-{flap}.png\"\n",
    "                exists = filename in files\n",
    "                print(f\"{filename}: {'✓' if exists else '✗'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "abd555eb-7a3e-4d2c-92cc-d03a34bdfb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_optimized_model(input_shape=(84, 84, 4)):\n",
    "    \"\"\"\n",
    "    Optimized lightweight model architecture\n",
    "    \"\"\"\n",
    "    input_img = Input(shape=input_shape)\n",
    "    \n",
    "    # Efficient CNN architecture\n",
    "    x = Conv2D(32, (8, 8), strides=(4, 4), activation='relu')(input_img)\n",
    "    x = Conv2D(64, (4, 4), strides=(2, 2), activation='relu')(x)\n",
    "    x = Conv2D(64, (3, 3), strides=(1, 1), activation='relu')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    \n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    output = Dense(2, activation='linear')(x)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=output)\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0002), loss='huber')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4774392f-862a-4fde-8f0e-cf61e844765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptimizedDQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=20000)\n",
    "        self.gamma = 0.99\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.99\n",
    "        self.learning_rate = 0.0002\n",
    "        self.batch_size = 64\n",
    "        self.min_replay_size = 500  # Wait for more samples before training\n",
    "        self.model = build_optimized_model(state_size)\n",
    "        self.target_model = build_optimized_model(state_size)\n",
    "        self.update_target_model()\n",
    "\n",
    "    def update_target_model(self):\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "    \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return np.random.randint(self.action_size)\n",
    "        state = np.expand_dims(state, axis=0)\n",
    "        act_values = self.model.predict(state, verbose=0)\n",
    "        return np.argmax(act_values[0])\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        if len(self.memory) < batch_size:\n",
    "            return\n",
    "        \n",
    "        # Use numpy arrays for better performance\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        states = np.array([exp[0] for exp in minibatch])\n",
    "        actions = np.array([exp[1] for exp in minibatch])\n",
    "        rewards = np.array([exp[2] for exp in minibatch])\n",
    "        next_states = np.array([exp[3] for exp in minibatch])\n",
    "        dones = np.array([exp[4] for exp in minibatch])\n",
    "        \n",
    "        # Batch predictions\n",
    "        target_values = self.target_model.predict(next_states, batch_size=batch_size, verbose=0)\n",
    "        targets = rewards + self.gamma * np.max(target_values, axis=1) * (1 - dones)\n",
    "        \n",
    "        target_f = self.model.predict(states, batch_size=batch_size, verbose=0)\n",
    "        for i, action in enumerate(actions):\n",
    "            target_f[i][action] = targets[i]\n",
    "        \n",
    "        self.model.fit(states, target_f, epochs=1, verbose=0, batch_size=batch_size)\n",
    "        \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "6f7884c0-20f6-4486-893b-933ca5a1d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_state_optimized(state):\n",
    "    \"\"\"\n",
    "    Optimized state preprocessing for 84x84 input\n",
    "    \"\"\"\n",
    "    state = cv2.resize(state, (84, 84), interpolation=cv2.INTER_AREA)\n",
    "    state = state.astype(np.float32) / 255.0\n",
    "    gray = cv2.cvtColor((state * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "    gray = np.expand_dims(gray, axis=-1).astype(np.float32) / 255.0\n",
    "    return np.concatenate([state, gray], axis=-1)\n",
    "\n",
    "def train_agent_optimized(n_episodes=500, update_target_freq=2):\n",
    "    \"\"\"Optimized training loop for lightweight model\"\"\"\n",
    "    # Environment setup\n",
    "    game = FlappyBird()\n",
    "    env = PLE(game, fps=30, display_screen=False)\n",
    "    env.init()\n",
    "    \n",
    "    # Initialize agent\n",
    "    state_size = (84, 84, 4)\n",
    "    action_size = len(env.getActionSet())\n",
    "    agent = OptimizedDQNAgent(state_size, action_size)\n",
    "    \n",
    "    # Training metrics\n",
    "    scores = []\n",
    "    recent_scores = deque(maxlen=100)\n",
    "    best_score = float('-inf')\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    # Progress bar\n",
    "    progress_bar = tqdm(range(n_episodes), desc='Training')\n",
    "    \n",
    "    for episode in progress_bar:\n",
    "        env.reset_game()\n",
    "        state = process_state_optimized(env.getScreenRGB())\n",
    "        total_reward = 0\n",
    "        steps = 0\n",
    "        episode_start_time = time.time()\n",
    "        \n",
    "        while not env.game_over():\n",
    "            action = agent.act(state)\n",
    "            raw_reward = env.act(env.getActionSet()[action])\n",
    "            next_state = process_state_optimized(env.getScreenRGB())\n",
    "            done = env.game_over()\n",
    "            \n",
    "            # Calculate reward\n",
    "            reward = calculate_optimized_reward(game.getGameState(), raw_reward, done, steps)\n",
    "            \n",
    "            # Store experience\n",
    "            agent.remember(state, action, reward, next_state, done)\n",
    "            \n",
    "            # Train if we have enough samples\n",
    "            if len(agent.memory) >= agent.min_replay_size:\n",
    "                agent.replay(agent.batch_size)\n",
    "            \n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            steps += 1\n",
    "        \n",
    "        # Update target network\n",
    "        if episode % update_target_freq == 0:\n",
    "            agent.update_target_model()\n",
    "        \n",
    "        # Update metrics\n",
    "        scores.append(total_reward)\n",
    "        recent_scores.append(total_reward)\n",
    "        avg_score = np.mean(recent_scores)\n",
    "        \n",
    "        # Save best model\n",
    "        if total_reward > best_score:\n",
    "            best_score = total_reward\n",
    "            agent.model.save('flappy_bird_best_model.keras')\n",
    "        \n",
    "        # Calculate speed metrics\n",
    "        episode_time = time.time() - episode_start_time\n",
    "        total_time = time.time() - training_start_time\n",
    "        avg_episode_time = total_time / (episode + 1)\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'Score': f'{total_reward:.1f}',\n",
    "            'Avg': f'{avg_score:.1f}',\n",
    "            'Best': f'{best_score:.1f}',\n",
    "            'Steps': steps,\n",
    "            'ε': f'{agent.epsilon:.2f}',\n",
    "            'Time/ep': f'{episode_time:.1f}s'\n",
    "        })\n",
    "        \n",
    "        # Save checkpoint every 50 episodes\n",
    "        if episode % 50 == 0 and episode > 0:\n",
    "            agent.model.save(f'flappy_bird_checkpoint_{episode}.keras')\n",
    "           \n",
    "        gc.collect()\n",
    "        tf.keras.backend.clear_session()\n",
    "    \n",
    "    return agent, scores\n",
    "\n",
    "def calculate_optimized_reward(game_state, raw_reward, done, steps):\n",
    "    \"\"\"Efficient reward calculation\"\"\"\n",
    "    if done:\n",
    "        return -5.0\n",
    "    \n",
    "    reward = 0.1  # Living reward\n",
    "    \n",
    "    # Quick calculations using numpy operations\n",
    "    player_y = game_state['player_y']\n",
    "    pipe_center_y = (game_state['next_pipe_top_y'] + game_state['next_pipe_bottom_y']) / 2\n",
    "    vertical_distance = abs(player_y - pipe_center_y)\n",
    "    pipe_distance = game_state['next_pipe_dist_to_player']\n",
    "    \n",
    "    # Vectorized reward calculation\n",
    "    reward += np.interp(vertical_distance, [0, 25, 50], [2.0, 0.5, 0.0])\n",
    "    reward += np.interp(pipe_distance, [0, 25, 50], [3.0, 1.0, 0.0])\n",
    "    \n",
    "    if raw_reward > 0:  # Passed through pipe\n",
    "        reward += 10.0\n",
    "    \n",
    "    if steps > 100:  # Survival bonus\n",
    "        reward *= 1.5\n",
    "    \n",
    "    return reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1f52184f-dc77-4995-8832-0c3fcfee244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(agent, n_episodes=10):\n",
    "    \"\"\"Test the trained agent\"\"\"\n",
    "    asset_path = setup_flappy_bird_environment()\n",
    "    if asset_path is None:\n",
    "        print(\"Failed to set up environment for testing. Exiting.\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        game = FlappyBird()\n",
    "        env = PLE(game, fps=30, display_screen=True)\n",
    "        env.init()\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to initialize game for testing: {e}\")\n",
    "        return\n",
    "    \n",
    "    agent.epsilon = 0  # Pure exploitation during testing\n",
    "    test_scores = []\n",
    "    \n",
    "    for episode in range(n_episodes):\n",
    "        env.reset_game()\n",
    "        state = preprocess_state(env.getScreenRGB())\n",
    "        total_reward = 0\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            action = agent.act(state)\n",
    "            reward = env.act(env.getActionSet()[action])\n",
    "            state = preprocess_state(env.getScreenRGB())\n",
    "            done = env.game_over()\n",
    "            total_reward += reward\n",
    "        \n",
    "        test_scores.append(total_reward)\n",
    "        print(f'Test Episode {episode + 1}: Total Reward = {total_reward}')\n",
    "    \n",
    "    print(f'Average Test Score: {np.mean(test_scores):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "9a59d154-da3d-43af-9715-855be8767b3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asset path: /anaconda/envs/azureml_py38/lib/python3.10/site-packages/ple/games/flappybird/assets\n",
      "Asset directory exists: True\n",
      "Contents of asset directory:\n",
      "['redbird-midflap.png', 'bluebird-midflap.png', 'background-day.png', 'redbird-upflap.png', 'base.png', 'yellowbird-downflap.png', 'pipe-red.png', 'background-night.png', 'pipe-green.png', 'bluebird-upflap.png', 'redbird-downflap.png', 'bluebird-downflap.png', 'yellowbird-upflap.png', 'yellowbird-midflap.png']\n"
     ]
    }
   ],
   "source": [
    "# Debug cell - Run this before main execution\n",
    "import os\n",
    "from ple import PLE\n",
    "import ple\n",
    "\n",
    "# Print asset directory information\n",
    "ple_path = os.path.dirname(ple.__file__)\n",
    "asset_path = os.path.join(ple_path, 'games', 'flappybird', 'assets')\n",
    "print(f\"Asset path: {asset_path}\")\n",
    "print(f\"Asset directory exists: {os.path.exists(asset_path)}\")\n",
    "if os.path.exists(asset_path):\n",
    "    print(\"Contents of asset directory:\")\n",
    "    print(os.listdir(asset_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3af848-a2d9-4405-a1e7-3f440d35c6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1/500, Score: 19.70, Game Score: -5.0, Avg Score: 19.70, Epsilon: 1.000, Steps: 58, Best Score: 19.70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/500 [02:09<10:30:20, 75.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2/500, Score: 42.10, Game Score: -5.0, Avg Score: 30.90, Epsilon: 0.945, Steps: 62, Best Score: 42.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/500 [04:04<12:56:18, 93.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 3/500, Score: 20.20, Game Score: -5.0, Avg Score: 27.33, Epsilon: 0.896, Steps: 53, Best Score: 42.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/500 [05:55<13:51:46, 100.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 4/500, Score: 11.50, Game Score: -5.0, Avg Score: 23.38, Epsilon: 0.851, Steps: 51, Best Score: 42.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/500 [07:28<13:26:10, 97.72s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 5/500, Score: 20.10, Game Score: -5.0, Avg Score: 22.72, Epsilon: 0.816, Steps: 42, Best Score: 42.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/500 [09:34<14:44:24, 107.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 6/500, Score: 10.90, Game Score: -5.0, Avg Score: 20.75, Epsilon: 0.772, Steps: 55, Best Score: 42.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 7/500 [11:51<16:03:48, 117.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 7/500, Score: 20.10, Game Score: -5.0, Avg Score: 20.66, Epsilon: 0.730, Steps: 57, Best Score: 42.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 8/500 [13:39<15:35:30, 114.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 8/500, Score: 18.00, Game Score: -5.0, Avg Score: 20.33, Epsilon: 0.697, Steps: 46, Best Score: 42.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 9/500 [14:51<13:48:07, 101.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 9/500, Score: 13.20, Game Score: -5.0, Avg Score: 19.53, Epsilon: 0.674, Steps: 33, Best Score: 42.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 10/500 [16:34<13:50:46, 101.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 10/500, Score: 22.10, Game Score: -5.0, Avg Score: 19.79, Epsilon: 0.643, Steps: 47, Best Score: 42.10\n",
      "Episode: 11/500, Score: 17.00, Game Score: -5.0, Avg Score: 19.54, Epsilon: 0.614, Steps: 46, Best Score: 42.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 12/500 [20:10<14:19:08, 105.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 12/500, Score: 23.20, Game Score: -5.0, Avg Score: 19.84, Epsilon: 0.583, Steps: 53, Best Score: 42.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 13/500 [22:06<14:41:41, 108.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 13/500, Score: 19.20, Game Score: -5.0, Avg Score: 19.79, Epsilon: 0.553, Steps: 53, Best Score: 42.10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 14/500 [24:39<16:29:17, 122.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 14/500, Score: 84.40, Game Score: -4.0, Avg Score: 24.41, Epsilon: 0.515, Steps: 70, Best Score: 84.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 15/500 [26:41<16:27:22, 122.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 15/500, Score: 23.00, Game Score: -5.0, Avg Score: 24.31, Epsilon: 0.487, Steps: 56, Best Score: 84.40\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    trained_agent, training_scores = train_agent(n_episodes=500)\n",
    "    if trained_agent is not None:\n",
    "        test_agent(trained_agent, n_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcbd476-5f9b-4c22-a348-58f5dfb14258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
