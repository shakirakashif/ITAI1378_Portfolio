{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5d5ea7-27cf-4407-9b11-d44a5077fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow tensorflow-hub tensorflow-datasets matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab7de23-4729-4539-8d90-a9bd95e5841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"TensorFlow Hub version:\", hub.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a4c293-ea22-4e20-b224-bf943beb7ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tiny_coco():\n",
    "    \"\"\"\n",
    "    Loads a very small portion of COCO dataset using direct slicing.\n",
    "    This approach is simpler and more reliable than trying to configure the download size.\n",
    "    \"\"\"\n",
    "    # Load just the first 50 training examples and 20 validation examples\n",
    "    train_ds, ds_info = tfds.load(\n",
    "        'coco/2017',\n",
    "        split='train[:50]',  # Take only first 50 training examples\n",
    "        with_info=True,\n",
    "        shuffle_files=True\n",
    "    )\n",
    "    \n",
    "    val_ds = tfds.load(\n",
    "        'coco/2017',\n",
    "        split='validation[:20]',  # Take only first 20 validation examples\n",
    "        shuffle_files=True\n",
    "    )\n",
    "    \n",
    "    print(\"Dataset loaded successfully!\")\n",
    "    return train_ds, val_ds, ds_info\n",
    "\n",
    "# Load our tiny datasets\n",
    "print(\"Loading tiny subset of COCO dataset...\")\n",
    "train_dataset, validation_dataset, dataset_info = load_tiny_coco()\n",
    "\n",
    "# Get class names\n",
    "class_names = dataset_info.features['objects']['label'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcff3a8-6f71-4077-af05-662f6bfe2f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_sample_images(dataset, num_images=2):\n",
    "    \"\"\"\n",
    "    Displays sample images from our dataset with their bounding boxes and labels.\n",
    "    This helps us verify that we've loaded the data correctly.\n",
    "    \"\"\"\n",
    "    for i, example in enumerate(dataset.take(num_images)):\n",
    "        # Get and convert the image\n",
    "        image = example[\"image\"].numpy()\n",
    "        \n",
    "        # Create a new figure for this image\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(image)\n",
    "        plt.title(f\"Sample image {i+1}\")\n",
    "        \n",
    "        # Draw each object's bounding box and label\n",
    "        for box, label in zip(example[\"objects\"][\"bbox\"], example[\"objects\"][\"label\"]):\n",
    "            # Get coordinates and convert from relative to absolute\n",
    "            ymin, xmin, ymax, xmax = box.numpy()\n",
    "            height, width = image.shape[0:2]\n",
    "            \n",
    "            # Create and add the rectangle\n",
    "            rect = patches.Rectangle(\n",
    "                (xmin * width, ymin * height),\n",
    "                (xmax - xmin) * width,\n",
    "                (ymax - ymin) * height,\n",
    "                linewidth=2,\n",
    "                edgecolor='r',\n",
    "                facecolor='none'\n",
    "            )\n",
    "            plt.gca().add_patch(rect)\n",
    "            \n",
    "            # Add the label\n",
    "            class_name = class_names[label.numpy()]\n",
    "            plt.text(\n",
    "                xmin * width,\n",
    "                ymin * height - 5,\n",
    "                class_name,\n",
    "                color='red',\n",
    "                bbox=dict(facecolor='white', alpha=0.7)\n",
    "            )\n",
    "        plt.show()\n",
    "\n",
    "# Display some examples to verify our data loading worked\n",
    "print(\"\\nDisplaying sample images from our tiny subset:\")\n",
    "display_sample_images(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faae3988-59dc-4503-b66d-5cf9d964fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a pre-trained object detection model\n",
    "detector = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c63c5fe-9067-457d-94cc-23133da144e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Detector and Visualize\n",
    "def run_detector_and_visualize(example):\n",
    "    image = example[\"image\"]\n",
    "    ground_truth_boxes = example[\"objects\"][\"bbox\"]\n",
    "\n",
    "    # Preprocess and run detection\n",
    "    converted_img = tf.image.convert_image_dtype(image, tf.uint8)[tf.newaxis, ...]\n",
    "    result = detector(converted_img)\n",
    "    result = {key: value.numpy() for key, value in result.items()}\n",
    "\n",
    "    # Visualize results (with ground truth for comparison)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.imshow(image)\n",
    "\n",
    "    # Ground truth boxes (VOC format is [xmin, ymin, xmax, ymax])\n",
    "    for box in ground_truth_boxes:\n",
    "        ymin, xmin, ymax, xmax = box\n",
    "        rect = patches.Rectangle((xmin * image.shape[1], ymin * image.shape[0]),\n",
    "                                (xmax - xmin) * image.shape[1], (ymax - ymin) * image.shape[0],\n",
    "                                linewidth=1, edgecolor='g', facecolor='none', label='Ground Truth')\n",
    "        plt.gca().add_patch(rect)\n",
    "\n",
    "    # Predicted boxes\n",
    "    for i, score in enumerate(result['detection_scores'][0]):\n",
    "        if score > 0.5:  # Confidence threshold\n",
    "            ymin, xmin, ymax, xmax = result['detection_boxes'][0][i]\n",
    "            class_id = int(result['detection_classes'][0][i])\n",
    "\n",
    "            # Handle invalid class IDs (classes outside the VOC dataset)\n",
    "            if class_id < len(class_names):\n",
    "                label = class_names[class_id]\n",
    "\n",
    "            rect = patches.Rectangle((xmin * image.shape[1], ymin * image.shape[0]),\n",
    "                                    (xmax - xmin) * image.shape[1], (ymax - ymin) * image.shape[0],\n",
    "                                    linewidth=1, edgecolor='r', facecolor='none', label='Predicted')\n",
    "            plt.gca().add_patch(rect)\n",
    "\n",
    "            # Moved plt.text to the correct loop for the predicted box\n",
    "            plt.text(xmin * image.shape[1], ymin * image.shape[0] - 5, f'{label}: {score:.2f}', color='white', backgroundcolor='r')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a44c2-5b4d-4d56-8dde-f59c5f986d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a few examples from the training set\n",
    "for example in train_dataset.take(2):  # Process 2 images\n",
    "    run_detector_and_visualize(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5468d348-3b77-4db8-920b-c0dd157a9e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nProcessing sample images from the dataset:\")\n",
    "for i, example in enumerate(train_dataset.take(3)):\n",
    "    print(f\"\\nSample image {i+1}\")\n",
    "    image = example['image'].numpy()\n",
    "\n",
    "    # Convert image to the correct format for the detector\n",
    "    converted_img = tf.image.convert_image_dtype(image, tf.uint8)[tf.newaxis, ...]\n",
    "\n",
    "    # Run detector on the image\n",
    "    detections = detector(converted_img)\n",
    "\n",
    "    # Convert the detections to numpy for plotting\n",
    "    result = {key: value.numpy() for key, value in detections.items()}\n",
    "\n",
    "    # Plot the detections\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(image)\n",
    "\n",
    "    # Draw boxes for detections with confidence > 0.5\n",
    "    for i, score in enumerate(result['detection_scores'][0]):\n",
    "        if score > 0.5:\n",
    "            ymin, xmin, ymax, xmax = result['detection_boxes'][0][i]\n",
    "            class_id = int(result['detection_classes'][0][i])\n",
    "\n",
    "            # Convert normalized coordinates to pixel coordinates\n",
    "            h, w = image.shape[0:2]\n",
    "            box = [xmin * w, ymin * h, (xmax - xmin) * w, (ymax - ymin) * h]\n",
    "\n",
    "            # Draw rectangle\n",
    "            rect = patches.Rectangle(\n",
    "                (box[0], box[1]), box[2], box[3],\n",
    "                linewidth=2, edgecolor='r', facecolor='none'\n",
    "            )\n",
    "            plt.gca().add_patch(rect)\n",
    "\n",
    "            # Add label\n",
    "            if class_id < len(class_names):\n",
    "                plt.text(box[0], box[1]-5,\n",
    "                        f'{class_names[class_id]}: {score:.2f}',\n",
    "                        color='red',\n",
    "                        bbox=dict(facecolor='white', alpha=0.8))\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc0c7e6-f07c-4075-93a6-71d19fa07957",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance(dataset, detector, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Enhanced evaluation function that uses a more sophisticated detection strategy\n",
    "    to improve both precision and recall.\n",
    "    \"\"\"\n",
    "    true_positives = 0\n",
    "    false_positives = 0\n",
    "    false_negatives = 0\n",
    "    \n",
    "    # Track performance metrics for analysis\n",
    "    detection_stats = {\n",
    "        'confidence_scores': [],\n",
    "        'iou_values': [],\n",
    "        'image_sizes': []\n",
    "    }\n",
    "\n",
    "    for example in dataset:\n",
    "        # Prepare image with proper preprocessing\n",
    "        image = example[\"image\"].numpy()\n",
    "        gt_boxes = example[\"objects\"][\"bbox\"].numpy()\n",
    "        gt_labels = example[\"objects\"][\"label\"].numpy()\n",
    "\n",
    "        # Store image size for analysis\n",
    "        detection_stats['image_sizes'].append(image.shape[:2])\n",
    "\n",
    "        # Ensure proper image formatting\n",
    "        if image.dtype != np.uint8:\n",
    "            image = tf.clip_by_value(image, 0, 255)\n",
    "            image = tf.cast(image, tf.uint8)\n",
    "        \n",
    "        # Add batch dimension and normalize\n",
    "        image_tensor = tf.expand_dims(image, 0)\n",
    "\n",
    "        # Run detection with error handling\n",
    "        try:\n",
    "            result = detector(image_tensor)\n",
    "            result = {key: value.numpy() for key, value in result.items()}\n",
    "        except Exception as e:\n",
    "            print(f\"Detection failed: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Get predictions and apply dynamic confidence thresholding\n",
    "        boxes = result['detection_boxes'][0]\n",
    "        scores = result['detection_scores'][0]\n",
    "        classes = result['detection_classes'][0].astype(int)\n",
    "\n",
    "        # Calculate dynamic confidence threshold based on score distribution\n",
    "        if len(scores) > 0:\n",
    "            # Use a more sophisticated threshold based on score distribution\n",
    "            score_mean = np.mean(scores)\n",
    "            score_std = np.std(scores)\n",
    "            dynamic_threshold = min(0.45, max(0.3, score_mean - score_std))\n",
    "        else:\n",
    "            dynamic_threshold = 0.45\n",
    "\n",
    "        # Filter predictions\n",
    "        mask = scores >= dynamic_threshold\n",
    "        boxes = boxes[mask]\n",
    "        scores = scores[mask]\n",
    "        classes = classes[mask]\n",
    "\n",
    "        # Store confidence scores for analysis\n",
    "        detection_stats['confidence_scores'].extend(scores)\n",
    "\n",
    "        # Track matched ground truth boxes\n",
    "        matched_gt = set()\n",
    "\n",
    "        # Sort predictions by confidence for better matching\n",
    "        sort_idx = np.argsort(scores)[::-1]\n",
    "        boxes = boxes[sort_idx]\n",
    "        scores = scores[sort_idx]\n",
    "        classes = classes[sort_idx]\n",
    "\n",
    "        # Compare predictions with ground truth\n",
    "        for i, (box, score, pred_class) in enumerate(zip(boxes, scores, classes)):\n",
    "            best_iou = 0\n",
    "            best_gt_idx = -1\n",
    "            \n",
    "            # Find best matching ground truth box\n",
    "            for j, gt_box in enumerate(gt_boxes):\n",
    "                if j not in matched_gt:\n",
    "                    iou = calculate_iou(gt_box, box)\n",
    "                    if iou > best_iou:\n",
    "                        best_iou = iou\n",
    "                        best_gt_idx = j\n",
    "\n",
    "            # Store IoU values for analysis\n",
    "            detection_stats['iou_values'].append(best_iou)\n",
    "\n",
    "            # Classify the detection using adaptive thresholding\n",
    "            if best_iou > iou_threshold and best_gt_idx >= 0:\n",
    "                if pred_class == gt_labels[best_gt_idx] + 1:\n",
    "                    true_positives += 1\n",
    "                    matched_gt.add(best_gt_idx)\n",
    "                else:\n",
    "                    false_positives += 1\n",
    "            else:\n",
    "                false_positives += 1\n",
    "\n",
    "        false_negatives += len(gt_boxes) - len(matched_gt)\n",
    "\n",
    "    # Calculate metrics\n",
    "    precision = true_positives / (true_positives + false_positives) if true_positives + false_positives > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if true_positives + false_negatives > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "\n",
    "    # Print detailed performance analysis\n",
    "    print(\"\\nDetailed Performance Analysis:\")\n",
    "    print(f\"IoU Threshold: {iou_threshold:.2f}\")\n",
    "    print(f\"\\nDetection Counts:\")\n",
    "    print(f\"True Positives: {true_positives} (correctly identified objects)\")\n",
    "    print(f\"False Positives: {false_positives} (incorrect detections)\")\n",
    "    print(f\"False Negatives: {false_negatives} (missed objects)\")\n",
    "    \n",
    "    print(f\"\\nPerformance Metrics:\")\n",
    "    print(f\"Precision: {precision:.2f} (accuracy of positive predictions)\")\n",
    "    print(f\"Recall: {recall:.2f} (proportion of actual objects detected)\")\n",
    "    print(f\"F1 Score: {f1:.2f} (balanced measure of precision and recall)\")\n",
    "\n",
    "    # Analyze detection statistics if we have data\n",
    "    if detection_stats['confidence_scores']:\n",
    "        mean_confidence = np.mean(detection_stats['confidence_scores'])\n",
    "        mean_iou = np.mean(detection_stats['iou_values'])\n",
    "        print(f\"\\nDetection Statistics:\")\n",
    "        print(f\"Average Confidence Score: {mean_confidence:.2f}\")\n",
    "        print(f\"Average IoU Score: {mean_iou:.2f}\")\n",
    "\n",
    "    return precision, recall, f1, detection_stats\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculates the Intersection over Union between two bounding boxes.\n",
    "    Box format: [ymin, xmin, ymax, xmax]\n",
    "    \"\"\"\n",
    "    # Calculate intersection coordinates\n",
    "    y1 = max(box1[0], box2[0])\n",
    "    x1 = max(box1[1], box2[1])\n",
    "    y2 = min(box1[2], box2[2])\n",
    "    x2 = min(box1[3], box2[3])\n",
    "    \n",
    "    # Calculate areas\n",
    "    intersection_area = max(0, y2 - y1) * max(0, x2 - x1)\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "    \n",
    "    # Calculate IoU\n",
    "    iou = intersection_area / union_area if union_area > 0 else 0\n",
    "    return iou\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Evaluating model performance...\")\n",
    "evaluate_model_performance(validation_dataset, detector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf9f88-355d-402e-b9a8-43f4080d756b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074a84b6-881c-4a3f-a407-2b5c6b34fd40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29977c0-f0c5-4ece-8f74-76b13df2713d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
